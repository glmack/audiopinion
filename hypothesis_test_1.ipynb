{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Postgres database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules\n",
    "\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#create connection\n",
    "conn = psycopg2.connect('dbname=pitchfork_reviews')\n",
    "cur = conn.cursor()\n",
    "\n",
    "#execute simple commands\n",
    "cur.execute(\"\"\"\n",
    "SELECT * FROM genres;\n",
    "\"\"\")\n",
    "\n",
    "genres = cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 1\n",
    "## Is there a statistical difference between 'metal' and 'jazz' music genres? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to choose what genres to compare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['electronic', 'metal', 'rock', None, 'rap', 'experimental',\n",
       "       'pop/r&b', 'folk/country', 'jazz', 'global'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load cast genres into a dataframe\n",
    "df_genres = pd.DataFrame(genres)\n",
    "\n",
    "#check unique values in genres\n",
    "df_genres[1].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose **metal** and **jazz** genres to see if there is a statistical difference within reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rock            9436\n",
       "electronic      3874\n",
       "experimental    1815\n",
       "rap             1559\n",
       "pop/r&b         1432\n",
       "metal            860\n",
       "folk/country     685\n",
       "jazz             435\n",
       "global           217\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check how many data entries we have for each genre\n",
    "df_genres[1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe for reviews scores for 'metal' genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "862"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a query from Postgres database to retrieve review scores for 'metal' genre\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "SELECT reviews.reviewid, reviews.score, genres.genre FROM reviews\n",
    "INNER JOIN genres ON reviews.reviewid = genres.reviewid\n",
    "WHERE genres.genre = 'metal';\n",
    "\"\"\")\n",
    "\n",
    "metal = cur.fetchall()\n",
    "len(metal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cast query result into a dataframe\n",
    "metal_df = pd.DataFrame(metal, columns=['id', 'score', 'genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "862"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(metal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems that there are 2 more rows than unique values for metal genre (862 in database query vs. 860 in rows where genre is 'metal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "859"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check number of unique values in our dataframe\n",
    "len(metal_df['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>9460</td>\n",
       "      <td>7.8</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>9460</td>\n",
       "      <td>7.8</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>9460</td>\n",
       "      <td>7.8</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>9460</td>\n",
       "      <td>7.8</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  score  genre\n",
       "555  9460    7.8  metal\n",
       "556  9460    7.8  metal\n",
       "557  9460    7.8  metal\n",
       "558  9460    7.8  metal"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see if the duplicates have all the same values for score columns\n",
    "metal_df[metal_df.id==9460]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "\n",
    "metal_df.drop_duplicates(subset =\"id\", \n",
    "                     keep='first', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>9460</td>\n",
       "      <td>7.8</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  score  genre\n",
       "555  9460    7.8  metal"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if we have just one value for id=9460\n",
    "metal_df[metal_df.id==9460]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe for reviews scores for 'jazz' genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a query from Postgres database to retrieve review scores for 'jazz' genre\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "SELECT reviews.reviewid, reviews.score, genres.genre FROM reviews\n",
    "INNER JOIN genres ON reviews.reviewid = genres.reviewid\n",
    "WHERE genres.genre = 'jazz';\n",
    "\"\"\")\n",
    "\n",
    "jazz = cur.fetchall()\n",
    "len(jazz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cast query result into a dataframe\n",
    "jazz_df = pd.DataFrame(jazz, columns=['id', 'score', 'genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22707</td>\n",
       "      <td>9.0</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22664</td>\n",
       "      <td>8.0</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22660</td>\n",
       "      <td>5.2</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22639</td>\n",
       "      <td>8.7</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22652</td>\n",
       "      <td>7.0</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  score genre\n",
       "0  22707    9.0  jazz\n",
       "1  22664    8.0  jazz\n",
       "2  22660    5.2  jazz\n",
       "3  22639    8.7  jazz\n",
       "4  22652    7.0  jazz"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check output\n",
    "jazz_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for id duplicates \n",
    "len(jazz_df['id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare 'metal' and 'jazz' scores we will look at the means of these two groups, taking a random sample of the size 50 from each group. We will assume that confidence level is 95%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null hypothesis**: there is no statistical difference between reviews scores for 'metal' and 'jazz' genres, that is, the difference in means is equal to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative Hypothesis**: there is difference between reviews scores for 'metal' and 'jazz' genres: the difference in means is not equal to 0.\n",
    "\n",
    "**Assumptions**:\n",
    "- data is independent\n",
    "- data collected randomely\n",
    "- data is approximately normally distribuited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check distribution of our data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(metal_df['score']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(jazz_df['score']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the plots of the distributions we can assume that data is approximately normally distribuited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean for metal genre is:  6.9470314318975515\n",
      "Mean for jazz genre is:  7.303908045977015\n"
     ]
    }
   ],
   "source": [
    "#calculate the means for 2 groups\n",
    "\n",
    "metal_mean = metal_df['score'].mean()\n",
    "jazz_mean = jazz_df['score'].mean()\n",
    "print('Mean for metal genre is: ', metal_mean)\n",
    "print('Mean for jazz genre is: ', jazz_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in means is:  -0.3568766140794635\n"
     ]
    }
   ],
   "source": [
    "diff_means = metal_mean - jazz_mean\n",
    "print('Difference in means is: ', diff_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate samples\n",
    "np.random.seed(0)\n",
    "sample_metal = np.random.choice(metal_df['score'], 50)\n",
    "sample_jazz = np.random.choice(jazz_df['score'], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.5, 6.6, 5.9, 6. , 1.9, 8.8, 7.4, 3.5, 7.2, 8. , 6.9, 5.1, 9. ,\n",
       "       6. , 7.8, 7.3, 7.8, 7. , 8.3, 5.7, 6.9, 6.1, 5.9, 5.8, 7.8, 5.7,\n",
       "       8.2, 7.8, 4.3, 9. , 5.5, 7.6, 4.3, 8. , 2. , 7.3, 8.3, 2. , 6.4,\n",
       "       7.6, 4.3, 1.9, 7.9, 7.4, 6.1, 7.6, 7.4, 6.9, 5.8, 7.1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.5620985891101116"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import fnctions module to compute t-statistic\n",
    "import functions\n",
    "\n",
    "t_stat = functions.twosample_tstatistic(sample_metal, sample_jazz)\n",
    "t_stat                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "#calculate t-test statistic and p-value using scipy library\n",
    "t_stat_check, p_value = stats.ttest_ind(sample_metal, sample_jazz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.5620985891101116"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_stat_check #corresponds to t_stat calculated manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005699396605738192"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#compare p-value with significance level\n",
    "print(p_value < 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "P-value is very small in our case which indicates that given null hypothesis is true, the probability that the results from the data we have would be due to a random chance. The probability of that is small enough to be able to reject the null hypothesis. So we can reject the null hypothesis and say that there is difference between review scores of 'metal' genre and 'jazz' genre.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2\n",
    "\n",
    "## If the same person does the review, does he/she score genres differently, in particular, 'metal' and 'jazz' genres?\n",
    "\n",
    "\n",
    "To answer this questions we will perform a 2-tailed paired t-test to see if multigenre reviewrs produce different review scores for 'metal' and 'jazz' genres in particular, since these genres are very different. We will take random samples of the size 50 to do the test\n",
    "\n",
    "**Null hypothesis**: the mean difference between paired observations is equal to zero\n",
    "\n",
    "**Alternative hypothesis**: the mean difference between paired observations is not equal to zero\n",
    "\n",
    "Confidence level: 95%\n",
    "\n",
    "Assumptions:\n",
    "- data is independent\n",
    "- data is approximately normally distribuited\n",
    "- data is continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe\n",
    "cur.execute(\"\"\"\n",
    "SELECT reviews.reviewid, reviews.author, reviews.score, genres.genre FROM reviews\n",
    "INNER JOIN genres ON reviews.reviewid = genres.reviewid\n",
    "WHERE genres.genre = 'jazz' OR genres.genre = 'metal';\n",
    "\"\"\")\n",
    "\n",
    "reviews = cur.fetchall()\n",
    "df_reviews = pd.DataFrame(reviews)\n",
    "df_reviews.columns = [i[0] for i in cur.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if there are duplicates on ids\n",
    "len(df_reviews['reviewid']) == len(df_reviews['reviewid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "df_reviews.drop_duplicates(subset =\"reviewid\", \n",
    "                     keep='first', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if there are duplicates on ids again after removing duplicates\n",
    "len(df_reviews['reviewid']) == len(df_reviews['reviewid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewid</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22721</td>\n",
       "      <td>zoe camp</td>\n",
       "      <td>7.9</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22702</td>\n",
       "      <td>sam sodomsky</td>\n",
       "      <td>7.5</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22707</td>\n",
       "      <td>seth colter-walls</td>\n",
       "      <td>9.0</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22559</td>\n",
       "      <td>savy reyes-kulkarni</td>\n",
       "      <td>7.7</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22664</td>\n",
       "      <td>philip sherburne</td>\n",
       "      <td>8.0</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewid               author  score  genre\n",
       "0     22721             zoe camp    7.9  metal\n",
       "1     22702         sam sodomsky    7.5  metal\n",
       "2     22707    seth colter-walls    9.0   jazz\n",
       "3     22559  savy reyes-kulkarni    7.7  metal\n",
       "4     22664     philip sherburne    8.0   jazz"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cast dataframe to a dictionry for further transformation\n",
    "review_dict = df_reviews.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty dictionary that will have this structure:\n",
    "#{'author_name': {'metal_scores': [], 'jazz_scores': []}}\n",
    "\n",
    "authors_genres_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through the review_dict to get the values for authors_genres_dict \n",
    "for i in review_dict:\n",
    "    \n",
    "    if i['author'] in authors_genres_dict.keys():\n",
    "        #update dictionary values for this author\n",
    "        if i['genre'] == 'metal':\n",
    "            authors_genres_dict[i['author']]['metal_scores'].append(i['score'])\n",
    "        else:\n",
    "            authors_genres_dict[i['author']]['jazz_scores'].append(i['score'])\n",
    "        \n",
    "    else:\n",
    "        #add this author name to authors_genres_dict keys\n",
    "        authors_genres_dict[i['author']] = {'metal_scores': [], 'jazz_scores': []}\n",
    "        \n",
    "        if i['genre'] == 'metal':\n",
    "            authors_genres_dict[i['author']]['metal_scores'].append(i['score'])\n",
    "        else:\n",
    "            authors_genres_dict[i['author']]['jazz_scores'].append(i['score'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove names that only reviewed one genre out of two\n",
    "authors_two_genres_dict = {}\n",
    "\n",
    "for key, value in authors_genres_dict.items():\n",
    "    if value['metal_scores'] != [] and value['jazz_scores'] != []:\n",
    "        authors_two_genres_dict[key] = {'metal_scores': np.mean(value['metal_scores']), 'jazz_scores': np.mean(value['jazz_scores'])}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_two_genres_df = pd.DataFrame.from_dict(authors_two_genres_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_two_genres_df.head()\n",
    "len(authors_two_genres_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a paired t-test using scipy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get samples of the size 50\n",
    "np.random.seed(0)\n",
    "\n",
    "sample_authors_two_genres_metal = np.random.choice(authors_two_genres_df['metal_scores'], 50)\n",
    "sample_authors_two_genres_jazz = np.random.choice(authors_two_genres_df['jazz_scores'], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = stats.ttest_rel(sample_authors_two_genres_metal, sample_authors_two_genres_jazz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic is:  -0.05944039423940176\n"
     ]
    }
   ],
   "source": [
    "print('t-statistic is: ', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value is:  0.952843103140735\n"
     ]
    }
   ],
   "source": [
    "print('p-value is: ', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "P-value represents the probability that given the null hypothesis is true, the data we had was the result of random chance. P-value is higher than out significance level aplha=0.05, so we **cannot reject the null hypothesis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 3\n",
    "## Looking at the scores produced by one author, are they different from the average scores given by the total of aythors? That, is any of the authors biased?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe\n",
    "cur.execute(\"\"\"\n",
    "SELECT reviews.reviewid, reviews.author, reviews.score, reviews.pub_date FROM reviews;\n",
    "\"\"\")\n",
    "\n",
    "reviews_test3 = cur.fetchall()\n",
    "df_reviews_test3 = pd.DataFrame(reviews_test3)\n",
    "df_reviews_test3.columns = [i[0] for i in cur.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if there are duplicates on ids\n",
    "len(df_reviews['reviewid']) == len(df_reviews['reviewid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewid</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "      <th>best_new_music</th>\n",
       "      <th>author</th>\n",
       "      <th>author_type</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>pub_weekday</th>\n",
       "      <th>pub_day</th>\n",
       "      <th>pub_month</th>\n",
       "      <th>pub_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10571</td>\n",
       "      <td>this is next</td>\n",
       "      <td>various artists</td>\n",
       "      <td>http://pitchfork.com/reviews/albums/10571-this...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>matt lemay</td>\n",
       "      <td>contributor</td>\n",
       "      <td>2007-08-22</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9464</td>\n",
       "      <td>shine on</td>\n",
       "      <td>jet</td>\n",
       "      <td>http://pitchfork.com/reviews/albums/9464-shine...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>ray suzuki</td>\n",
       "      <td>contributor</td>\n",
       "      <td>2006-10-02</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6383</td>\n",
       "      <td>relaxation of the asshole</td>\n",
       "      <td>robert pollard</td>\n",
       "      <td>http://pitchfork.com/reviews/albums/6383-relax...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>eric carr</td>\n",
       "      <td>contributor</td>\n",
       "      <td>2005-04-20</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5607</td>\n",
       "      <td>travistan</td>\n",
       "      <td>travis morrison</td>\n",
       "      <td>http://pitchfork.com/reviews/albums/5607-travi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>chris dahlen</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-09-27</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6255</td>\n",
       "      <td>liz phair</td>\n",
       "      <td>liz phair</td>\n",
       "      <td>http://pitchfork.com/reviews/albums/6255-liz-p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>matt lemay</td>\n",
       "      <td>contributor</td>\n",
       "      <td>2003-06-24</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7342</td>\n",
       "      <td>nyc ghosts &amp; flowers</td>\n",
       "      <td>sonic youth</td>\n",
       "      <td>http://pitchfork.com/reviews/albums/7342-nyc-g...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>brent dicrescenzo</td>\n",
       "      <td>contributor</td>\n",
       "      <td>2000-04-30</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewid                      title           artist  \\\n",
       "0     10571               this is next  various artists   \n",
       "1      9464                   shine on              jet   \n",
       "2      6383  relaxation of the asshole   robert pollard   \n",
       "3      5607                  travistan  travis morrison   \n",
       "4      6255                  liz phair        liz phair   \n",
       "5      7342       nyc ghosts & flowers      sonic youth   \n",
       "\n",
       "                                                 url  score  best_new_music  \\\n",
       "0  http://pitchfork.com/reviews/albums/10571-this...    0.0               0   \n",
       "1  http://pitchfork.com/reviews/albums/9464-shine...    0.0               0   \n",
       "2  http://pitchfork.com/reviews/albums/6383-relax...    0.0               0   \n",
       "3  http://pitchfork.com/reviews/albums/5607-travi...    0.0               0   \n",
       "4  http://pitchfork.com/reviews/albums/6255-liz-p...    0.0               0   \n",
       "5  http://pitchfork.com/reviews/albums/7342-nyc-g...    0.0               0   \n",
       "\n",
       "              author  author_type    pub_date  pub_weekday  pub_day  \\\n",
       "0         matt lemay  contributor  2007-08-22            2       22   \n",
       "1         ray suzuki  contributor  2006-10-02            0        2   \n",
       "2          eric carr  contributor  2005-04-20            2       20   \n",
       "3       chris dahlen         None  2004-09-27            0       27   \n",
       "4         matt lemay  contributor  2003-06-24            1       24   \n",
       "5  brent dicrescenzo  contributor  2000-04-30            6       30   \n",
       "\n",
       "   pub_month  pub_year  \n",
       "0          8      2007  \n",
       "1         10      2006  \n",
       "2          4      2005  \n",
       "3          9      2004  \n",
       "4          6      2003  \n",
       "5          4      2000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check rows that have 0.0 review score to see if it is necessary to drop them\n",
    "cur.execute(\"\"\"\n",
    "SELECT * FROM reviews WHERE reviews.score=0;\n",
    "\"\"\")\n",
    "\n",
    "zero_score_reviews = cur.fetchall()\n",
    "df_zero_score_reviews = pd.DataFrame(zero_score_reviews)\n",
    "df_zero_score_reviews.columns = [i[0] for i in cur.description]\n",
    "\n",
    "df_zero_score_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After going through the reviews with 0 scores, we came to a conclusion that there is no reason to drop those rows since all but 1 actually have a review text. There is no reason to believe that the score 0 was not chosen intentionally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date into datetime object\n",
    "df_reviews_test3.pub_date = df_reviews_test3.pub_date.apply(lambda x: pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18393 entries, 0 to 18392\n",
      "Data columns (total 4 columns):\n",
      "reviewid    18393 non-null int64\n",
      "author      18393 non-null object\n",
      "score       18393 non-null float64\n",
      "pub_date    18393 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(1)\n",
      "memory usage: 574.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#check if converted correctly\n",
    "df_reviews_test3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cast dataframe to dictionary\n",
    "review_dict_test3 = df_reviews_test3.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions\n",
    "\n",
    "author_scores_dict = functions.get_author_scores(review_dict_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#author_scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new dictionary with authors who did more than 50 reviews\n",
    "#the higher the number of reviews, the closer to a normal distribution the data is\n",
    "author_scores_50 = {}\n",
    "\n",
    "for key, value in author_scores_dict.items():\n",
    "    if len(value['scores']) >= 50:\n",
    "        author_scores_50[key] = value\n",
    "\n",
    "        \n",
    "#how many authors are in the dictionary?\n",
    "len(author_scores_50.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary with means per author\n",
    "author_scores_50_means = {}\n",
    "\n",
    "for key, value in author_scores_50.items():\n",
    "    author_scores_50_means[key] = np.mean(value['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#author_scores_50_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a function that will perform the following hypothesis test for each author:\n",
    "\n",
    "**Null Hypothesis**: the mean of the author's review is the same as the population mean (mean of all scores).\n",
    "\n",
    "**Alternative hypothesis**: the mean of an author's review is different from the population meean\n",
    "\n",
    "Chosen confidence level: 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate popuaition mean and standard deviation\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "SELECT score FROM reviews;\n",
    "\"\"\")\n",
    "\n",
    "scores = cur.fetchall()\n",
    "scores_df = pd.DataFrame(scores, columns=['score'])\n",
    "scores_mean = scores_df['score'].mean()\n",
    "scores_std = scores_df['score'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2936745021540692"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_mean\n",
    "scores_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot sample distributions to check for normality: uncomment when necessary\n",
    "\n",
    "#for value in author_scores_50.values():\n",
    "    #plt.hist(value['scores'])\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases the data in the samples seem to be approximately normally distribuited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select random state for reproducable results\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('katherine st. asaph', 0.040226914457122814)],\n",
       " [('andy beta', 0.00011609478342203273)],\n",
       " [('ian cohen', 4.618678127090948e-05)],\n",
       " [('marc masters', 4.909656224112512e-07)],\n",
       " [('philip sherburne', 5.378917677589627e-13)],\n",
       " [('seth colter walls', 1.7140963562389597e-15)],\n",
       " [('evan rytlewski', 5.158150703983876e-09)],\n",
       " [('mark richardson', 4.8776477707834445e-06)],\n",
       " [('eric harvey', 0.017596360392426437)],\n",
       " [('mike powell', 0.005639004908092863)],\n",
       " [(\"andy o'connor\", 0.00034800225719793177)],\n",
       " [('jason heller', 0.017578610786354094)],\n",
       " [('steven hyden', 0.023337779233351015)],\n",
       " [('grayson haver currin', 1.3350357313985206e-09)],\n",
       " [('rob mitchum', 0.0030402087182545795)],\n",
       " [('david drake', 0.011886141491954626)],\n",
       " [('aaron leitko', 0.0006029616504546511)],\n",
       " [('brandon stosuy', 1.8499965493644354e-06)],\n",
       " [('zach kelly', 0.006656172379542307)],\n",
       " [('tim finney', 0.014974760189480255)],\n",
       " [('matthew murphy', 0.002021750997003414)],\n",
       " [('joe tangari', 0.02588622841216998)],\n",
       " [('jordan sargent', 0.004377849368499789)],\n",
       " [('kim kelly', 1.3329318529603895e-08)],\n",
       " [('lindsay zoladz', 0.018328779163519805)],\n",
       " [('david raposa', 0.006815679895146381)],\n",
       " [('joshua love', 0.001044442064954949)],\n",
       " [('scott plagenhoef', 0.004536066442976017)],\n",
       " [('joshua klein', 1.3679851756080693e-05)],\n",
       " [('liz colville', 3.604495500858185e-05)],\n",
       " [('adam moerder', 2.2609691648900814e-05)],\n",
       " [('mark richard-san', 1.912003956425621e-07)],\n",
       " [('brent dicrescenzo', 0.009550520155646834)],\n",
       " [('david m. pecoraro', 0.03095463726969958)],\n",
       " [('paul cooper', 0.0378636420838647)],\n",
       " [('christopher dare', 1.57671121371889e-05)]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the results using samples of the size 50\n",
    "biased_authors = functions.get_biased_authors_with_samples(author_scores_50, scores_mean, 0.05)\n",
    "biased_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biased_authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The function returned a list of author names and p-values in cases, where p-value was lower than our alpha level of 0.05. So in those cases we have to reject the null hypothesis that the mean of the sample is equal to the mean of the population. In this series of experiments 36 out of 85 (around 40%) authors have highter or lower average review score than the average of all dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close connection to database\n",
    "\n",
    "#conn.commit()\n",
    "#conn.rollback()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
